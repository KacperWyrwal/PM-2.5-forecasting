{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebed900",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8375f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import re \n",
    "\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "\n",
    "from typing import Iterable, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0ac20",
   "metadata": {},
   "source": [
    "# Overview \n",
    "In this notebook, we will read the csv files with data from all available CPCB station between Jan 2019 and Jan 2020. We clean the resulting dataframes slightly, joint each station with its correponding GPS coordinates and combine all dataframes into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ac86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cpcb(path: str, index_col: str = 'From Date') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a path to file with data from a selected CPCB station, returns it as a conveniently parsed \n",
    "    DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\n",
    "            path, \n",
    "            na_values=['None', ''], \n",
    "            dtype={'PM2.5': float}, \n",
    "            parse_dates = [index_col], \n",
    "            usecols = [index_col, 'PM2.5'], \n",
    "            date_parser=lambda x: datetime.strptime(x, '%d-%m-%Y %H:%M')\n",
    "        ).rename(columns={'PM2.5': 'pm2_5', index_col: 'timestamp'}).set_index('timestamp')\n",
    "\n",
    "\n",
    "def read_all_cpcb(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recursively reads all files in a directory via the read_cpcb function and combines them into a single \n",
    "    DataFrame. If the given directory contains a file incompatible with the read_cpcb function, an error\n",
    "    will be thrown.\n",
    "    \"\"\"\n",
    "    return pd.concat(\n",
    "        read_cpcb(path=os.path.join(root, file)).assign(site=file.split('.')[0]) \n",
    "                  for root, _, files in os.walk(path) for file in files\n",
    "    )\n",
    "\n",
    "\n",
    "def match_prefix(string: str, prefixes: Iterable[str]) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Returns prefix matching the given string from an iterable of prefixes. If not matching prefix is found, \n",
    "    returns None. \n",
    "    \"\"\"\n",
    "    for prefix in prefixes:\n",
    "        if string.startswith(prefix):\n",
    "            return prefix \n",
    "\n",
    "\n",
    "def clean_2019_jan_june(from_path: str, site_names: Iterable[str], to_path: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Transform the 2019 Jan-June data into the format consistent with the rest of the CPCB files and saves\n",
    "    it at the given to_path. If no to_path is provided, to_path is set to from_path concatenated with \n",
    "    \"_cleaned\".\n",
    "    \"\"\"\n",
    "    if to_path is None:\n",
    "        to_path = f'{from_path}_cleaned'\n",
    "    if not os.path.exists(to_path):\n",
    "        os.makedirs(to_path)\n",
    "    \n",
    "    for file_name in os.listdir(from_path):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(from_path, file_name), \n",
    "            usecols=['From.Date', 'To.Date.x', 'PM2.5']\n",
    "        ).rename(columns={'From.Date': 'From Date', 'To.Date.x': 'To Date'})\n",
    "        \n",
    "        # Save with station name matching the site locations file\n",
    "        if (file_name_cleaned := match_prefix(file_name, site_names)) is not None: \n",
    "                file_name = file_name_cleaned\n",
    "        df.to_csv(os.path.join(to_path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946355e",
   "metadata": {},
   "source": [
    "### Cleaning 2019 Jan-June data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d46ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your path to the site locations xlsx file\n",
    "site_locations_path = '../CPCB/site_locations_040619.xlsx' \n",
    "site_locations_df = pd.read_excel(site_locations_path, \n",
    "                    names=['site name', 'gpsLatitude', 'gpsLongitude', 'site'], \n",
    "                    dtype={'gpsLatitude': float, 'gpsLongitude': float}, \n",
    "                    usecols=['gpsLatitude', 'gpsLongitude', 'site'], \n",
    "                    index_col='site',\n",
    "                   )\n",
    "site_to_gps = site_locations_df.T.to_dict(orient='list')\n",
    "\n",
    "# Replace with your path to the directory containing all CPCB data between Jan and June 2019\n",
    "path_2019_jan_june = '../CPCB/CPCB Data/CPCB Data 2019/Jan-June'\n",
    "clean_2019_jan_june(from_path=path_2019_jan_june, site_names=site_to_gps.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3e952",
   "metadata": {},
   "source": [
    "### Merging cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8496cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>474.50</td>\n",
       "      <td>Mundka_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>351.79</td>\n",
       "      <td>Burari_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>309.47</td>\n",
       "      <td>Noi_Sector62_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>254.00</td>\n",
       "      <td>Farida_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>361.50</td>\n",
       "      <td>Alipur_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>33.44</td>\n",
       "      <td>Lodhi_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>50.00</td>\n",
       "      <td>Jawaha_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>94.00</td>\n",
       "      <td>Jahang_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>65.48</td>\n",
       "      <td>NSIT_D_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>63.00</td>\n",
       "      <td>Wazirp_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pm2_5           site\n",
       "timestamp                                 \n",
       "2019-01-01 00:00:00  474.50        Mundka_\n",
       "2019-01-01 00:00:00  351.79        Burari_\n",
       "2019-01-01 00:00:00  309.47  Noi_Sector62_\n",
       "2019-01-01 00:00:00  254.00        Farida_\n",
       "2019-01-01 00:00:00  361.50        Alipur_\n",
       "...                     ...            ...\n",
       "2020-01-31 17:45:00   33.44         Lodhi_\n",
       "2020-01-31 17:45:00   50.00        Jawaha_\n",
       "2020-01-31 17:45:00   94.00        Jahang_\n",
       "2020-01-31 17:45:00   65.48        NSIT_D_\n",
       "2020-01-31 17:45:00   63.00        Wazirp_\n",
       "\n",
       "[973264 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace with your path to the outer-most directory of all CPCB data\n",
    "# Remember to remove the uncleaned 2019 jan-june data from this directory\n",
    "path_all_data = '../CPCB/CPCB Data/'\n",
    "df = read_all_cpcb(path=path_all_data).sort_index()\n",
    "df = df[df['site'].isin(site_to_gps.keys())]\n",
    "\n",
    "# Replace with your desired path where the merged data will be saved\n",
    "path_merged_data = '../TF/data/CPCB_all'\n",
    "df.to_csv(path_merged_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff754c5",
   "metadata": {},
   "source": [
    "Adding coordinates to stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a08a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>gpsLatitude</th>\n",
       "      <th>gpsLongitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>474.50</td>\n",
       "      <td>28.684678</td>\n",
       "      <td>77.076574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>351.79</td>\n",
       "      <td>28.725650</td>\n",
       "      <td>77.201157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>309.47</td>\n",
       "      <td>28.624548</td>\n",
       "      <td>77.357710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>254.00</td>\n",
       "      <td>28.408842</td>\n",
       "      <td>77.309908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>361.50</td>\n",
       "      <td>28.814792</td>\n",
       "      <td>77.098075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>33.44</td>\n",
       "      <td>28.591825</td>\n",
       "      <td>77.227307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>50.00</td>\n",
       "      <td>28.580280</td>\n",
       "      <td>77.233829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>94.00</td>\n",
       "      <td>28.732820</td>\n",
       "      <td>77.170633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>65.48</td>\n",
       "      <td>28.609090</td>\n",
       "      <td>77.032541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 17:45:00</th>\n",
       "      <td>63.00</td>\n",
       "      <td>28.699793</td>\n",
       "      <td>77.165453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pm2_5  gpsLatitude  gpsLongitude\n",
       "timestamp                                             \n",
       "2019-01-01 00:00:00  474.50    28.684678     77.076574\n",
       "2019-01-01 00:00:00  351.79    28.725650     77.201157\n",
       "2019-01-01 00:00:00  309.47    28.624548     77.357710\n",
       "2019-01-01 00:00:00  254.00    28.408842     77.309908\n",
       "2019-01-01 00:00:00  361.50    28.814792     77.098075\n",
       "...                     ...          ...           ...\n",
       "2020-01-31 17:45:00   33.44    28.591825     77.227307\n",
       "2020-01-31 17:45:00   50.00    28.580280     77.233829\n",
       "2020-01-31 17:45:00   94.00    28.732820     77.170633\n",
       "2020-01-31 17:45:00   65.48    28.609090     77.032541\n",
       "2020-01-31 17:45:00   63.00    28.699793     77.165453\n",
       "\n",
       "[973264 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_merged_data, index_col='timestamp', parse_dates=['timestamp'])\n",
    "df[['gpsLatitude', 'gpsLongitude']] = df['site'].map(site_to_gps).\\\n",
    "    transform({'gpsLatitude': itemgetter(0), 'gpsLongitude': itemgetter(1)})\n",
    "df.drop(columns='site', inplace=True)\n",
    "\n",
    "# After adding the coordinates, save in the same place \n",
    "df.to_csv(path_merged_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1ed6f",
   "metadata": {},
   "source": [
    "### Combine CPCB data with DAPHNE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feee7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dap(file_name: str) -> bool: \n",
    "    \"\"\"\n",
    "    Verify that file_name represents a DAPHNE file i.e. check that the file_name starts with either \"DAP\" \n",
    "    or \"DMC\".\n",
    "    \"\"\"\n",
    "    match = re.match(r'(?P<code>[A-Z]{3})', file_name)\n",
    "    if match is None: \n",
    "        return False \n",
    "    \n",
    "    return match.group('code') in ['DAP', 'DMC']\n",
    "\n",
    "\n",
    "def read_dap(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a daphne csv file from the given path. If the file name in the path does not start with \n",
    "    either \"DAP\" or \"DMC\", an error is returned. \n",
    "    \"\"\"\n",
    "    if not is_dap(os.path.basename(path)):\n",
    "        return None \n",
    "    return pd.read_csv(\n",
    "        path, \n",
    "        index_col='timestamp',\n",
    "        parse_dates=['timestamp'],\n",
    "        usecols = ['pm2_5', 'gpsLatitude', 'gpsLongitude', 'timestamp']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c0d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>gpsLatitude</th>\n",
       "      <th>gpsLongitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:00:00</th>\n",
       "      <td>104.549465</td>\n",
       "      <td>28.569899</td>\n",
       "      <td>77.280083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:01:00</th>\n",
       "      <td>104.525328</td>\n",
       "      <td>28.569924</td>\n",
       "      <td>77.280082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:02:00</th>\n",
       "      <td>103.990309</td>\n",
       "      <td>28.569925</td>\n",
       "      <td>77.280082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:03:00</th>\n",
       "      <td>103.235306</td>\n",
       "      <td>28.569923</td>\n",
       "      <td>77.280083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:04:00</th>\n",
       "      <td>102.500352</td>\n",
       "      <td>28.569871</td>\n",
       "      <td>77.280125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 06:56:00</th>\n",
       "      <td>175.675800</td>\n",
       "      <td>28.568823</td>\n",
       "      <td>77.209016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 06:57:00</th>\n",
       "      <td>167.558224</td>\n",
       "      <td>28.568824</td>\n",
       "      <td>77.209043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 06:58:00</th>\n",
       "      <td>158.351632</td>\n",
       "      <td>28.568807</td>\n",
       "      <td>77.208993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 06:58:13</th>\n",
       "      <td>135.199570</td>\n",
       "      <td>28.506170</td>\n",
       "      <td>77.341057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 07:02:13</th>\n",
       "      <td>139.499027</td>\n",
       "      <td>28.506170</td>\n",
       "      <td>77.341057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pm2_5  gpsLatitude  gpsLongitude\n",
       "timestamp                                                 \n",
       "2018-08-08 05:00:00  104.549465    28.569899     77.280083\n",
       "2018-08-08 05:01:00  104.525328    28.569924     77.280082\n",
       "2018-08-08 05:02:00  103.990309    28.569925     77.280082\n",
       "2018-08-08 05:03:00  103.235306    28.569923     77.280083\n",
       "2018-08-08 05:04:00  102.500352    28.569871     77.280125\n",
       "...                         ...          ...           ...\n",
       "2020-02-01 06:56:00  175.675800    28.568823     77.209016\n",
       "2020-02-01 06:57:00  167.558224    28.568824     77.209043\n",
       "2020-02-01 06:58:00  158.351632    28.568807     77.208993\n",
       "2020-02-01 06:58:13  135.199570    28.506170     77.341057\n",
       "2020-02-01 07:02:13  139.499027    28.506170     77.341057\n",
       "\n",
       "[1648234 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace with your path to all DAPHNE data\n",
    "path_to_dap = '../TF/data/DAP_all_processed'\n",
    "dap = read_dap(path=path_to_dap)\n",
    "cpcb_dap_merged = pd.concat((df, dap)).sort_index()\n",
    "\n",
    "# Replace with your desired path where the merged data will be saved\n",
    "path_cpcb_dap_merged = '../TF/data/DAP_CPCB_all'\n",
    "cpcb_dap_merged.to_csv(path_cpcb_dap_merged)\n",
    "cpcb_dap_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
